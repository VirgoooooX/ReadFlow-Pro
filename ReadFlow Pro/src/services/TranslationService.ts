import { DatabaseService } from '../database/DatabaseService';
import { SettingsService } from './SettingsService';
import { logger } from './rss/RSSUtils';

/**
 * ç¿»è¯‘ç¼“å­˜æ¡ç›®
 */
export interface TranslationCacheEntry {
  id?: number;
  originalText: string;
  translatedText: string;
  sourceLang: string;
  targetLang: string;
  source: string;
  createdAt?: Date;
}

/**
 * ç¿»è¯‘æœåŠ¡ - ä½¿ç”¨LLMç¿»è¯‘å¥å­ï¼Œå¹¶ç¼“å­˜åˆ°æœ¬åœ°æ•°æ®åº“
 */
export class TranslationService {
  private static instance: TranslationService;
  private databaseService: DatabaseService;
  private settingsService: SettingsService;

  private constructor() {
    this.databaseService = DatabaseService.getInstance();
    this.settingsService = SettingsService.getInstance();
  }

  public static getInstance(): TranslationService {
    if (!TranslationService.instance) {
      TranslationService.instance = new TranslationService();
    }
    return TranslationService.instance;
  }

  /**
   * ç¿»è¯‘å¥å­ï¼ˆä¼˜å…ˆæœ¬åœ°ç¼“å­˜ï¼Œåå¤‡LLMï¼‰
   */
  public async translateSentence(
    text: string,
    sourceLang: string = 'en',
    targetLang: string = 'zh'
  ): Promise<string | null> {
    try {
      const normalizedText = text.trim();
      
      // 1. é¦–å…ˆå°è¯•ä»æœ¬åœ°ç¼“å­˜æŸ¥è¯¢
      const cachedResult = await this.getCachedTranslation(normalizedText, sourceLang, targetLang);
      if (cachedResult) {
        logger.info(`âœ… ä»ç¼“å­˜è·å–ç¿»è¯‘: ${normalizedText.substring(0, 50)}...`);
        return cachedResult.translatedText;
      }

      // 2. æœ¬åœ°ç¼“å­˜æ²¡æœ‰ï¼Œè°ƒç”¨LLMç¿»è¯‘
      logger.info(`ğŸ” è°ƒç”¨LLMç¿»è¯‘: ${normalizedText.substring(0, 50)}...`);
      const translation = await this.translateWithLLM(normalizedText, sourceLang, targetLang);
      
      if (translation) {
        // 3. å°†LLMç»“æœå­˜å…¥æœ¬åœ°ç¼“å­˜
        await this.cacheTranslation({
          originalText: normalizedText,
          translatedText: translation,
          sourceLang,
          targetLang,
          source: 'llm',
        });
        
        return translation;
      }

      return null;
    } catch (error) {
      logger.error('Error translating sentence:', error);
      return null;
    }
  }


  /**
   * ä»æœ¬åœ°ç¼“å­˜è·å–ç¿»è¯‘
   */
  private async getCachedTranslation(
    text: string,
    sourceLang: string,
    targetLang: string
  ): Promise<TranslationCacheEntry | null> {
    try {
      const results = await this.databaseService.executeQuery(
        'SELECT * FROM translation_cache WHERE original_text = ? AND source_lang = ? AND target_lang = ? LIMIT 1',
        [text, sourceLang, targetLang]
      );

      if (results.length > 0) {
        const row = results[0];
        return {
          id: row.id,
          originalText: row.original_text,
          translatedText: row.translated_text,
          sourceLang: row.source_lang,
          targetLang: row.target_lang,
          source: row.source,
          createdAt: row.created_at ? new Date(row.created_at) : undefined,
        };
      }

      return null;
    } catch (error) {
      logger.error('Error getting cached translation:', error);
      return null;
    }
  }

  /**
   * ç¼“å­˜ç¿»è¯‘ç»“æœ
   */
  private async cacheTranslation(entry: TranslationCacheEntry): Promise<void> {
    try {
      const now = new Date().toISOString();

      await this.databaseService.executeStatement(
        `INSERT INTO translation_cache (original_text, translated_text, source_lang, target_lang, source, created_at)
         VALUES (?, ?, ?, ?, ?, ?)`,
        [entry.originalText, entry.translatedText, entry.sourceLang, entry.targetLang, entry.source, now]
      );
      
      logger.info(`ğŸ’¾ å·²ç¼“å­˜ç¿»è¯‘: ${entry.originalText.substring(0, 50)}...`);
    } catch (error) {
      logger.error('Error caching translation:', error);
    }
  }

  /**
   * è°ƒç”¨LLMç¿»è¯‘
   */
  private async translateWithLLM(
    text: string,
    sourceLang: string,
    targetLang: string
  ): Promise<string | null> {
    try {
      const llmSettings = await this.settingsService.getLLMSettings();
      
      if (!llmSettings?.apiKey) {
        logger.warn('LLM API key not configured');
        return null;
      }

      const prompt = this.buildTranslationPrompt(text, sourceLang, targetLang);
      
      // è°ƒç”¨LLM API
      const response = await this.callLLMAPI(llmSettings, prompt);
      
      if (response) {
        // è®°å½•ä½¿ç”¨ç»Ÿè®¡
        await this.logUsage('translation', llmSettings.provider, llmSettings.model);
        return response.trim();
      }

      return null;
    } catch (error) {
      logger.error('Error translating with LLM:', error);
      // è®°å½•å¤±è´¥ç»Ÿè®¡
      const llmSettings = await this.settingsService.getLLMSettings();
      if (llmSettings) {
        await this.logUsage('translation', llmSettings.provider, llmSettings.model, false);
      }
      return null;
    }
  }


  /**
   * æ„å»ºç¿»è¯‘æç¤ºè¯
   */
  private buildTranslationPrompt(text: string, sourceLang: string, targetLang: string): string {
    const langMap: { [key: string]: string } = {
      'en': 'è‹±è¯­',
      'zh': 'ä¸­æ–‡',
      'ja': 'æ—¥è¯­',
      'ko': 'éŸ©è¯­',
      'fr': 'æ³•è¯­',
      'de': 'å¾·è¯­',
      'es': 'è¥¿ç­ç‰™è¯­',
    };

    const sourceLangName = langMap[sourceLang] || sourceLang;
    const targetLangName = langMap[targetLang] || targetLang;

    return `è¯·å°†ä»¥ä¸‹${sourceLangName}æ–‡æœ¬ç¿»è¯‘æˆ${targetLangName}ã€‚åªéœ€è¦è¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚

åŸæ–‡ï¼š${text}

ç¿»è¯‘ï¼š`;
  }

  /**
   * è°ƒç”¨LLM API
   */
  private async callLLMAPI(settings: any, prompt: string): Promise<string | null> {
    try {
      const { provider, apiKey, baseUrl, model, customModelName, temperature, maxTokens } = settings;
      
      let apiEndpoint = baseUrl || 'https://api.openai.com/v1';
      let actualModel = customModelName || model || 'gpt-3.5-turbo';
      
      // æ ¹æ®æä¾›å•†è°ƒæ•´è¯·æ±‚æ ¼å¼
      if (provider === 'anthropic') {
        return await this.callAnthropicAPI(apiEndpoint, apiKey, actualModel, prompt, temperature, maxTokens);
      } else {
        // OpenAI å…¼å®¹æ ¼å¼
        return await this.callOpenAICompatibleAPI(apiEndpoint, apiKey, actualModel, prompt, temperature, maxTokens);
      }
    } catch (error) {
      logger.error('Error calling LLM API:', error);
      return null;
    }
  }

  /**
   * è°ƒç”¨OpenAIå…¼å®¹API
   */
  private async callOpenAICompatibleAPI(
    baseUrl: string,
    apiKey: string,
    model: string,
    prompt: string,
    temperature: number = 0.3,
    maxTokens: number = 1024
  ): Promise<string | null> {
    // ç¡®ä¿baseUrlæ ¼å¼æ­£ç¡®ï¼Œç§»é™¤æœ«å°¾æ–œæ 
    const cleanBaseUrl = baseUrl.replace(/\/+$/, '');
    
    logger.info('ğŸ” è°ƒç”¨LLMç¿»è¯‘:' + prompt.substring(0, 50) + '...');
    logger.info('ğŸ¯ APIåœ°å€:' + `${cleanBaseUrl}/chat/completions`);
    logger.info('ğŸ¤– æ¨¡å‹:' + model);
    
    const response = await fetch(`${cleanBaseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model,
        messages: [
          { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚' },
          { role: 'user', content: prompt }
        ],
        temperature,
        max_tokens: maxTokens,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text().catch(() => 'Unknown error');
      logger.error('âŒ APIè¯·æ±‚å¤±è´¥:', response.status, errorText);
      throw new Error(`API request failed: ${response.status}`);
    }

    const data = await response.json();
    const result = data.choices?.[0]?.message?.content || null;
    logger.info('âœ… ç¿»è¯‘ç»“æœ:' + result?.substring(0, 50) + '...');
    return result;
  }


  /**
   * è°ƒç”¨Anthropic API
   */
  private async callAnthropicAPI(
    baseUrl: string,
    apiKey: string,
    model: string,
    prompt: string,
    temperature: number = 0.3,
    maxTokens: number = 1024
  ): Promise<string | null> {
    const response = await fetch(`${baseUrl}/messages`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': apiKey,
        'anthropic-version': '2023-06-01',
      },
      body: JSON.stringify({
        model,
        max_tokens: maxTokens,
        messages: [
          { role: 'user', content: prompt }
        ],
        temperature,
      }),
    });

    if (!response.ok) {
      throw new Error(`Anthropic API request failed: ${response.status}`);
    }

    const data = await response.json();
    return data.content?.[0]?.text || null;
  }

  /**
   * è®°å½•LLMä½¿ç”¨ç»Ÿè®¡
   */
  private async logUsage(
    requestType: string,
    provider: string,
    model: string,
    success: boolean = true
  ): Promise<void> {
    try {
      const now = new Date().toISOString();
      await this.databaseService.executeStatement(
        `INSERT INTO llm_usage_stats (request_type, provider, model, success, created_at)
         VALUES (?, ?, ?, ?, ?)`,
        [requestType, provider, model, success ? 1 : 0, now]
      );
    } catch (error) {
      logger.error('Error logging usage:', error);
    }
  }

  /**
   * è·å–ä½¿ç”¨ç»Ÿè®¡
   */
  public async getUsageStats(): Promise<{
    total: number;
    monthly: number;
    byType: { [key: string]: number };
  }> {
    try {
      // ç¡®ä¿æ•°æ®åº“å·²åˆå§‹åŒ–
      await this.databaseService.initializeDatabase();
      
      // æ€»è¯·æ±‚æ•°
      const totalResult = await this.databaseService.executeQuery(
        'SELECT COUNT(*) as count FROM llm_usage_stats WHERE success = 1'
      ).catch(() => [{ count: 0 }]);
      
      // æœ¬æœˆè¯·æ±‚æ•°
      const startOfMonth = Math.floor(new Date(new Date().getFullYear(), new Date().getMonth(), 1).getTime() / 1000);
      const monthlyResult = await this.databaseService.executeQuery(
        'SELECT COUNT(*) as count FROM llm_usage_stats WHERE success = 1 AND created_at >= ?',
        [startOfMonth]
      ).catch(() => [{ count: 0 }]);
      
      // æŒ‰ç±»å‹ç»Ÿè®¡
      const byTypeResult = await this.databaseService.executeQuery(
        'SELECT request_type, COUNT(*) as count FROM llm_usage_stats WHERE success = 1 GROUP BY request_type'
      ).catch(() => []);
      
      const byType: { [key: string]: number } = {};
      byTypeResult.forEach((row: any) => {
        byType[row.request_type] = row.count;
      });
      
      return {
        total: totalResult[0]?.count || 0,
        monthly: monthlyResult[0]?.count || 0,
        byType,
      };
    } catch (error) {
      logger.error('Error getting usage stats:', error);
      return { total: 0, monthly: 0, byType: {} };
    }
  }

  /**
   * è·å–ç¿»è¯‘å†å²
   */
  public async getTranslationHistory(limit: number = 50): Promise<TranslationCacheEntry[]> {
    try {
      // ç¡®ä¿æ•°æ®åº“å·²åˆå§‹åŒ–
      await this.databaseService.initializeDatabase();
      
      const results = await this.databaseService.executeQuery(
        'SELECT * FROM translation_cache ORDER BY created_at DESC LIMIT ?',
        [limit]
      ).catch(() => []);

      return results.map((row: any) => ({
        id: row.id,
        originalText: row.original_text,
        translatedText: row.translated_text,
        sourceLang: row.source_lang,
        targetLang: row.target_lang,
        source: row.source,
        createdAt: row.created_at ? new Date(row.created_at * 1000) : undefined,
      }));
    } catch (error) {
      logger.error('Error getting translation history:', error);
      return [];
    }
  }

  /**
   * æ¸…é™¤ç¿»è¯‘ç¼“å­˜
   */
  public async clearCache(): Promise<void> {
    try {
      await this.databaseService.executeStatement('DELETE FROM translation_cache');
      logger.info('ç¿»è¯‘ç¼“å­˜å·²æ¸…é™¤');
    } catch (error) {
      logger.error('Error clearing translation cache:', error);
    }
  }

}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const translationService = TranslationService.getInstance();
